{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "pruning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X-PjE3nQOEiT",
        "SoG0UqPh4ynC",
        "PMErQBiG5OC1",
        "PulpsFXH5SE8",
        "8_AXZJAp5cAV",
        "ieUPb3DN5ikE",
        "7iwt6C9B55FK",
        "YW8EIaxOXRQC",
        "Awq4P4rWT5H2",
        "W5GARpziUALq",
        "wYN_frGCYDEX",
        "df-199rbniU7",
        "fsJcVq5dzmZz",
        "EmS-HnFF6qJk",
        "5DQ2801NA1nV",
        "pPyPnnra0zxg"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROumSd2iWk7A"
      },
      "source": [
        "# MAGNITUDE BASED PRUNING FOR LSTM BASED DECODER\n",
        "1. Prune Training\n",
        "2. Prune Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tnA1esHIpc7",
        "outputId": "f0e25de1-d659-49d1-b7e4-fbebcef7ea98"
      },
      "source": [
        "'''\n",
        "Mount Drive\n",
        "To search for decoder.py in mounted drive, set path\n",
        "Install tensorflow-model-optimization\n",
        "'''\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('####') # Add path\n",
        "! pip install tensorflow-model-optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting tensorflow-model-optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.18.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (0.1.5)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHM0upk3G2N0"
      },
      "source": [
        "import numpy as np\n",
        "import pickle as pk\n",
        "from decoder import *\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "\n",
        "import tempfile\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVD9aJhwTBka"
      },
      "source": [
        "'''\n",
        "Define folderpath for further operations\n",
        "'''\n",
        "FOLDERPATH = '####' # Add path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B22tukpwVYjs"
      },
      "source": [
        "## PRUNE TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBi7vAu_G2N1"
      },
      "source": [
        "'''\n",
        "BUILD PRUNING MODEL FUNCTION\n",
        "----------------------------\n",
        "Run this cell to run the build_pruning_model() function.\n",
        "This function takes in model, begin sparsity and final sparsity\n",
        "as inputs and return a pruned model architecture. Re-train\n",
        "the pruned architecture to recover model generalization.\n",
        "'''\n",
        "def build_pruning_model(model,bsp,fsp):\n",
        "  pruning_params = {'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=bsp,\n",
        "                                                                  final_sparsity=fsp,\n",
        "                                                                  begin_step=0,\n",
        "                                                                  end_step=5000)}\n",
        "  model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
        "  model_for_pruning.compile(optimizer='adam',\n",
        "                              loss='categorical_crossentropy')\n",
        "\n",
        "  return model_for_pruning\n",
        "\n",
        "\n",
        "'''\n",
        "ALTERNATIVE LAYER WISE PRUNING\n",
        "------------------------------\n",
        "Not attaching pruning wrapper to Embedding layer\n",
        "'''\n",
        "def apply_pruning_to_dense(layer):\n",
        "  pruning_params = {'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0,\n",
        "                                                                  final_sparsity=0.8,\n",
        "                                                                  begin_step=0,\n",
        "                                                                  end_step=5000)}\n",
        "  if isinstance(layer, tf.keras.layers.Add):\n",
        "    return layer\n",
        "  return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
        "\n",
        "def build_pruning_model_layers(base_model):\n",
        "  model_for_pruning = tf.keras.models.clone_model(\n",
        "    base_model,\n",
        "    clone_function=apply_pruning_to_dense,\n",
        "    )\n",
        "  model_for_pruning.compile(optimizer='adam',\n",
        "                              loss='categorical_crossentropy')\n",
        "  return model_for_pruning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CVezHwIG2N1"
      },
      "source": [
        "'''\n",
        "LOAD BASELINE MODEL\n",
        "'''\n",
        "baseline_model = load_model(FOLDERPATH+'/models-v2/baselines/pruned50-ResNet-baseline-LSTM.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTPepOqXG2N1",
        "outputId": "283605cd-0617-446a-cd16-3ad33af1deff"
      },
      "source": [
        "'''\n",
        "BUILD PRUNED MODEL, HYPER-PARAMETERS AND CALLBACKS\n",
        "--------------------------------------------------\n",
        "Set begin sparsity, final sparsity and number of epochs for re-training.\n",
        "'''\n",
        "bsp, fsp = 0, 0.50\n",
        "epochs = 5\n",
        "\n",
        "pruned_model = build_pruning_model(baseline_model,bsp,fsp)\n",
        "# pruned_model = build_pruning_model_layers(baseline_model)\n",
        "print(pruned_model.summary())\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:200: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 1000)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_embedding ( (None, 34, 256)      3880450     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout (Pr (None, 1000)         1           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dropout_1 ( (None, 34, 256)      1           prune_low_magnitude_embedding[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dense (Prun (None, 256)          512258      prune_low_magnitude_dropout[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_lstm (Prune (None, 256)          1049603     prune_low_magnitude_dropout_1[0][\n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_add (PruneL (None, 256)          1           prune_low_magnitude_dense[0][0]  \n",
            "                                                                 prune_low_magnitude_lstm[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dense_1 (Pr (None, 256)          131330      prune_low_magnitude_add[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "prune_low_magnitude_dense_2 (Pr (None, 7579)         3888029     prune_low_magnitude_dense_1[0][0]\n",
            "==================================================================================================\n",
            "Total params: 9,461,673\n",
            "Trainable params: 4,735,387\n",
            "Non-trainable params: 4,726,286\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOG6Ns7JG2N2",
        "outputId": "cb4a6718-e894-4a95-a98d-36f1df29abed"
      },
      "source": [
        "'''\n",
        "PRUNE TRAINING\n",
        "--------------\n",
        "Define featuresname, load training set and re-train model\n",
        "featuresname: name of the encoder features list file\n",
        "'''\n",
        "featuresname = 'features_ResNetP50'\n",
        "\n",
        "# load training dataset \n",
        "filename = FOLDERPATH+'dataset/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "train_descriptions = load_clean_descriptions(FOLDERPATH+'dataset/descriptions.txt', train)\n",
        "train_features = load_photo_features(FOLDERPATH+'dataset/{:}.pkl'.format(featuresname), train)\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "maxlength = max_length(train_descriptions)\n",
        "\n",
        "# train the model, run epochs manually and save after each epoch\n",
        "# modelname = 'baseline-VGG16-pruned80-LSTM'\n",
        "steps = len(train_descriptions)\n",
        "for i in range(1,epochs+1):\n",
        "\tgenerator = data_generator(train_descriptions, train_features, tokenizer, maxlength, vocab_size)\n",
        "\thistory = pruned_model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1,callbacks=callbacks)\n",
        "\t# if i%5 == 0:\n",
        "\t# \tpruned_model.save(FOLDERPATH+'models-v2/'+modelname+'_ep_' + str(i) + '.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-4298404403f3>:23: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "   1/6000 [..............................] - ETA: 0s - loss: 5.5589WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "6000/6000 [==============================] - 212s 35ms/step - loss: 3.7849\n",
            "6000/6000 [==============================] - 209s 35ms/step - loss: 3.6813\n",
            "6000/6000 [==============================] - 209s 35ms/step - loss: 3.6274\n",
            "6000/6000 [==============================] - 208s 35ms/step - loss: 3.5892\n",
            "6000/6000 [==============================] - 207s 35ms/step - loss: 3.5595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHnA-TC7G2N2",
        "outputId": "a193dcd3-552b-4431-d92a-f0bb9168dce8"
      },
      "source": [
        "'''\n",
        "STRIP FOR EXPORT MODEL AND SAVE\n",
        "-------------------------------\n",
        "Before saving, set the following in filename \n",
        "1. Which model used?\n",
        "2. What's pruning bsp and fsp\n",
        "3. What's decoder architecture?\n",
        "'''\n",
        "modelname = 'pruned50-ResNet-pruned50-LSTM'\n",
        "striped_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "print(striped_model.summary())\n",
        "striped_model.save(FOLDERPATH+'models-v2/pruned/'+modelname+'.h5')\n",
        "\n",
        "# '''\n",
        "# SAVE HISTORY AS WELL\n",
        "# '''\n",
        "# pk.dump(history,open(FOLDERPATH+'model-history/'+modelname+'.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 1000)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 34, 256)      1940224     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1000)         0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 34, 256)      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          256256      dropout[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 256)          525312      dropout_1[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 256)          0           dense[1][0]                      \n",
            "                                                                 lstm[1][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          65792       add[1][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 7579)         1947803     dense_1[1][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,735,387\n",
            "Trainable params: 4,735,387\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9Lh1db1Vh8E"
      },
      "source": [
        "## PRUNE EVALUATION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcErcD7zG2N3"
      },
      "source": [
        "'''\n",
        "EVALUATE THE PRUNED MODEL\n",
        "-------------------------\n",
        "Provide model and features list file name. \n",
        "The function prints BLEU scores and time taken to process.\n",
        "'''\n",
        "\n",
        "def evaluate_call(model,feat_fname):\n",
        "\n",
        "  # load training dataset (6K)\n",
        "  filename = FOLDERPATH+'dataset/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "  train = load_set(filename)\n",
        "  train_descriptions = load_clean_descriptions(FOLDERPATH+'dataset/descriptions.txt', train)\n",
        "  tokenizer = create_tokenizer(train_descriptions)\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "  maxlength = max_length(train_descriptions)\n",
        "\n",
        "  # load test set\n",
        "  filename = FOLDERPATH+'dataset/Flickr8k_text/Flickr_8k.testImages.txt'\n",
        "  test = load_set(filename)\n",
        "  test_descriptions = load_clean_descriptions(FOLDERPATH+'dataset/descriptions.txt', test)\n",
        "  test_features = load_photo_features(FOLDERPATH+'dataset/{:}.pkl'.format(feat_fname), test)\n",
        "\n",
        "  # evaluate model\n",
        "  start = time.time()\n",
        "  evaluate_model(model, test_descriptions, test_features, tokenizer, maxlength)\n",
        "  print(\"\\nTime taken: \", (time.time()-start)/60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-PjE3nQOEiT"
      },
      "source": [
        "### VGG16 Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoG0UqPh4ynC"
      },
      "source": [
        "##### BASELINE VGG16 AND 50% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqw6A1sbUa5U",
        "outputId": "8fa41512-bf85-4ed7-c07b-e12326994ffa"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'baseline-VGG16-pruned50-LSTM.h5'\n",
        "featuresname = 'features_VGG'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.534086\n",
            "BLEU-2: 0.281099\n",
            "BLEU-3: 0.181940\n",
            "BLEU-4: 0.076307\n",
            "\n",
            "Time taken:  5.583005964756012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMErQBiG5OC1"
      },
      "source": [
        "##### BASELINE VGG16 AND 80% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeFfb7_DgH0W",
        "outputId": "7871b2a9-e8f1-419d-fab0-1200e9648993"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'baseline-VGG16-pruned80-LSTM.h5'\n",
        "featuresname = 'features_VGG'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.599606\n",
            "BLEU-2: 0.299564\n",
            "BLEU-3: 0.169109\n",
            "BLEU-4: 0.070046\n",
            "\n",
            "Time taken:  4.449543042977651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PulpsFXH5SE8"
      },
      "source": [
        "##### BASELINE VGG16 AND 90% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4yWsQpSgIt4",
        "outputId": "31ffc5b0-3965-44a0-f509-444dbe0b74a9"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'baseline-VGG16-pruned90-LSTM.h5'\n",
        "featuresname = 'features_VGG'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.521724\n",
            "BLEU-2: 0.238366\n",
            "BLEU-3: 0.396328\n",
            "BLEU-4: 0.450047\n",
            "\n",
            "Time taken:  3.842176659901937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_AXZJAp5cAV"
      },
      "source": [
        "##### QUANTIZED VGG16 AND 50% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOxo11tEyywf",
        "outputId": "61d2cf68-75bd-4d01-c01a-afa0077ebb05"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'quantized-VGG16-pruned50-LSTM.h5'\n",
        "featuresname = 'features_VGGQ'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.502071\n",
            "BLEU-2: 0.260290\n",
            "BLEU-3: 0.177183\n",
            "BLEU-4: 0.078390\n",
            "\n",
            "Time taken:  6.2438020745913185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieUPb3DN5ikE"
      },
      "source": [
        "##### QUANTIZED VGG16 AND 80% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn5BvMuO4co7",
        "outputId": "0d433453-e0e7-4a2f-a2ef-9f48bb5dd0f2"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'quantized-VGG16-pruned80-LSTM.h5'\n",
        "featuresname = 'features_VGGQ'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.518027\n",
            "BLEU-2: 0.254723\n",
            "BLEU-3: 0.132197\n",
            "BLEU-4: 0.049560\n",
            "\n",
            "Time taken:  4.9500048716863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iwt6C9B55FK"
      },
      "source": [
        "##### QUANTIZED VGG16 AND 90% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY9T6QmB6DCY",
        "outputId": "63a8d88c-e3b5-48da-b082-53a59ca8f071"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'quantized-VGG16-pruned90-LSTM.h5'\n",
        "featuresname = 'features_VGGQ'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.557672\n",
            "BLEU-2: 0.254117\n",
            "BLEU-3: 0.146251\n",
            "BLEU-4: 0.060697\n",
            "\n",
            "Time taken:  4.359605813026429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW8EIaxOXRQC"
      },
      "source": [
        "##### PRUNED50 VGG16 AND 50% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EolAbnTSXYrC",
        "outputId": "f4b16aee-c2b6-42b3-832b-9086de783b5b"
      },
      "source": [
        "modelname = 'pruned50-VGG16-pruned50-LSTM.h5'\n",
        "featuresname = 'features_VGGP50'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/pruned/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.418220\n",
            "BLEU-2: 0.169478\n",
            "BLEU-3: 0.107443\n",
            "BLEU-4: 0.043284\n",
            "\n",
            "Time taken:  6.213016577561697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awq4P4rWT5H2"
      },
      "source": [
        "### RESNET Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5GARpziUALq"
      },
      "source": [
        "##### BASELINE RESNET AND 50% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j97bgceGUFBn",
        "outputId": "74fc12de-c02d-4981-dc30-412bba7d6edb"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'baseline-ResNet-pruned50-LSTM.h5'\n",
        "featuresname = 'features_ResNet'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.514461\n",
            "BLEU-2: 0.267497\n",
            "BLEU-3: 0.186613\n",
            "BLEU-4: 0.082742\n",
            "\n",
            "Time taken:  5.7076051791508995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYN_frGCYDEX"
      },
      "source": [
        "##### BASELINE RESNET AND *80*% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prnqKOcMYDgV",
        "outputId": "edac040d-8128-4602-b915-ac3eb2f19727"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'baseline-ResNet-pruned80-LSTM.h5'\n",
        "featuresname = 'features_ResNet'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.509572\n",
            "BLEU-2: 0.244919\n",
            "BLEU-3: 0.145254\n",
            "BLEU-4: 0.062147\n",
            "\n",
            "Time taken:  5.000856161117554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df-199rbniU7"
      },
      "source": [
        "##### BASELINE RESNET AND *90*% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xXhDwOyniwV",
        "outputId": "37c9424f-f7ab-4320-e05c-8f002b957c4b"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'baseline-ResNet-pruned90-LSTM.h5'\n",
        "featuresname = 'features_ResNet'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.540337\n",
            "BLEU-2: 0.262965\n",
            "BLEU-3: 0.133826\n",
            "BLEU-4: 0.049221\n",
            "\n",
            "Time taken:  5.124466558297475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsJcVq5dzmZz"
      },
      "source": [
        "##### QUANTIZED RESNET AND *50*% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doe4GK2nHcxo",
        "outputId": "73b2457f-d6e8-42c5-bb04-676c6552b371"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'quantized-ResNet-pruned50-LSTM.h5'\n",
        "featuresname = 'features_ResNetQ'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.524480\n",
            "BLEU-2: 0.277066\n",
            "BLEU-3: 0.191862\n",
            "BLEU-4: 0.091881\n",
            "\n",
            "Time taken:  6.653377254803975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmS-HnFF6qJk"
      },
      "source": [
        "##### QUANTIZED RESNET AND *80*% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eMs0xR4Hcqo",
        "outputId": "e8588bc0-66cf-48e5-e134-0cc9305d88a8"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'quantized-ResNet-pruned80-LSTM.h5'\n",
        "featuresname = 'features_ResNetQ'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.529209\n",
            "BLEU-2: 0.259698\n",
            "BLEU-3: 0.166630\n",
            "BLEU-4: 0.077764\n",
            "\n",
            "Time taken:  5.359142843882243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DQ2801NA1nV"
      },
      "source": [
        "##### QUANTIZED RESNET AND *90*% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq50lt1BA1OW",
        "outputId": "5bf7d84b-d87a-4655-f9da-b92daa593352"
      },
      "source": [
        "'''\n",
        "EVALUATE MODEL\n",
        "--------------\n",
        "Load model, call evaluate\n",
        "'''\n",
        "modelname = 'quantized-ResNet-pruned90-LSTM.h5'\n",
        "featuresname = 'features_ResNetQ'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.427553\n",
            "BLEU-2: 0.176371\n",
            "BLEU-3: 0.110494\n",
            "BLEU-4: 0.040035\n",
            "\n",
            "Time taken:  5.916788101196289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPyPnnra0zxg"
      },
      "source": [
        "##### PRUNED50 RESNET AND 50% PRUNED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acv73HO704Zv",
        "outputId": "4c172ec6-7309-44c8-bf7a-9f22f1fa567a"
      },
      "source": [
        "modelname = 'pruned50-ResNet-pruned50-LSTM.h5'\n",
        "featuresname = 'features_ResNetP50'\n",
        "model_eval = load_model(FOLDERPATH+'models-v2/pruned/'+modelname)\n",
        "model_eval.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "evaluate_call(model_eval,featuresname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "BLEU-1: 0.418220\n",
            "BLEU-2: 0.169478\n",
            "BLEU-3: 0.107443\n",
            "BLEU-4: 0.043284\n",
            "\n",
            "Time taken:  4.798878228664398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-S7zVz6Lqm"
      },
      "source": [
        "### ROUGH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLDxQvKuFTvS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}