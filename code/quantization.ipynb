{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quantization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ivDYXA9lRhyg",
        "oc9-E3z_rCvu",
        "EERf5qjkMzGs",
        "m7r1O5AsXGTT",
        "1U5C_BM7VUbZ",
        "FM--lzU9Pnze",
        "0VbQObkcrLxK",
        "rOtQPy2hN23V",
        "2GtJtRtQjWBV",
        "W32LJBFwvMul",
        "wjixHgXevXHK",
        "2o3qnJCCRniC",
        "jr9NSZL8KSg8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a36-1-XtJ6qM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970ab48d-0255-4acd-c4dd-70ece3070b4b"
      },
      "source": [
        "'''\n",
        "Mount Drive\n",
        "To search for decoder.py in mounted drive, set path\n",
        "Install tensorflow-model-optimization\n",
        "'''\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('####') # Add path\n",
        "! pip install tensorflow-model-optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting tensorflow-model-optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.18.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (0.1.5)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM0CQ7cmKGbS"
      },
      "source": [
        "import numpy as np\n",
        "import pickle as pk\n",
        "from decoder import *\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x5bUwp9VKM9"
      },
      "source": [
        "'''\n",
        "Define folderpath for further operations\n",
        "'''\n",
        "FOLDERPATH = '####' # Add path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygJifT59z_JD"
      },
      "source": [
        "'''\n",
        "GLOBAL QUANTIZATION FUNCTIONS\n",
        "-----------------------------\n",
        "1. Save quant model\n",
        "2. Get model size\n",
        "'''\n",
        "def save_quant(model,inpshape,modeldir,ty):\n",
        "  run_model = tf.function(lambda x: model(x))\n",
        "  concrete_func = run_model.get_concrete_function([tf.TensorSpec([1,inpshape], model.inputs[0].dtype),\n",
        "                                                  tf.TensorSpec([1,34], model.inputs[1].dtype)])\n",
        "  model.save(FOLDERPATH+'models-v2/'+ty+'/'+modeldir, save_format=\"tf\", signatures=concrete_func)\n",
        "\n",
        "def get_quant_model_size(model):\n",
        "  import tempfile\n",
        "  import os\n",
        "\n",
        "  _, quant_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "  with open(quant_file, 'wb') as f:\n",
        "    f.write(model)\n",
        "\n",
        "  print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivDYXA9lRhyg"
      },
      "source": [
        "### QUANTIZATION AWARE TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7zPMNlNKK21"
      },
      "source": [
        "'''\n",
        "FUNCTION QUANTIZATION AWARE TRAINING\n",
        "------------------------------------\n",
        "1. Initialize a model\n",
        "2. Load weights for better accuracy (optional but recommended)\n",
        "3. Annotate layers to quantize\n",
        "4. Compile model\n",
        "'''\n",
        "def get_quant_model(featuresname,lw=True,modelname=None):\n",
        "\n",
        "\t# load training dataset \n",
        "\tfilename = FOLDERPATH+'dataset/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "\ttrain = load_set(filename)\n",
        "\ttrain_descriptions = load_clean_descriptions(FOLDERPATH+'dataset/descriptions.txt', train)\n",
        "\ttrain_features = load_photo_features(FOLDERPATH+'dataset/{:}.pkl'.format(featuresname), train)\n",
        "\ttokenizer = create_tokenizer(train_descriptions)\n",
        "\tvocab_size = len(tokenizer.word_index) + 1\n",
        "\tmaxlength = max_length(train_descriptions)\n",
        "\ttrain_data = (train_descriptions, train_features, tokenizer, maxlength, vocab_size)\n",
        "\n",
        "\t# LOAD MODEL FOR BETTER ACCURACY\n",
        "\tinputshape = list(train_features.values())[0].shape[1]\n",
        "\tmodel = define_model(vocab_size,maxlength,inputshape)\n",
        "\tif lw:\n",
        "\t\tmodel.load_weights(FOLDERPATH+'models-v2/baselines/'+modelname)\n",
        "\n",
        "\t# INITIALIZE QUANTIZATION\n",
        "\tdef apply_quantization_to_dense(layer):\n",
        "\t\tif isinstance(layer, tf.keras.layers.Dense) or isinstance(layer,tf.keras.layers.Dropout):\n",
        "\t\t\treturn tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "\t\treturn layer\n",
        "\n",
        "\tannotated_model = tf.keras.models.clone_model(model,clone_function=apply_quantization_to_dense)\n",
        "\tquant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "\tquant_aware_model.summary()\n",
        "\n",
        "\tquant_aware_model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "\n",
        "\treturn quant_aware_model, train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_98vkC3VvyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6480c2-c4fe-467a-ffd1-76c91542faa4"
      },
      "source": [
        "'''\n",
        "QUANTIZATION AWARE TRAINING\n",
        "'''\n",
        "featuresname = 'features_ResNetP50Q'\n",
        "baselinemodelname = 'pruned50quant-ResNet-baseline-LSTM.h5'\n",
        "lw = True\n",
        "if not lw:\n",
        "\tbaselinemodelname = None\n",
        "epochs = 10\n",
        "quant_aware_model, train_data = get_quant_model(featuresname,lw,baselinemodelname)\n",
        "steps = len(train_data[0])\n",
        "for i in range(1,epochs+1):\n",
        "\tgenerator = data_generator(train_data[0],train_data[1],train_data[2],train_data[3],train_data[4])\n",
        "\tquant_aware_model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "quantize_layer_1 (QuantizeLayer (None, 100)          3           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 34, 256)      1940224     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "quant_dropout_2 (QuantizeWrappe (None, 100)          1           quantize_layer_1[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "quant_dropout_3 (QuantizeWrappe (None, 34, 256)      1           embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "quant_dense_3 (QuantizeWrapper) (None, 256)          25861       quant_dropout_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 256)          525312      quant_dropout_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256)          0           quant_dense_3[0][0]              \n",
            "                                                                 lstm_1[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "quant_dense_4 (QuantizeWrapper) (None, 256)          65797       add_1[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "quant_dense_5 (QuantizeWrapper) (None, 7579)         1947808     quant_dense_4[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 4,505,007\n",
            "Trainable params: 4,504,987\n",
            "Non-trainable params: 20\n",
            "__________________________________________________________________________________________________\n",
            "6000/6000 [==============================] - 163s 27ms/step - loss: 3.1249\n",
            "6000/6000 [==============================] - 168s 28ms/step - loss: 3.0244\n",
            "6000/6000 [==============================] - 168s 28ms/step - loss: 2.9831\n",
            "6000/6000 [==============================] - 166s 28ms/step - loss: 2.9526\n",
            "6000/6000 [==============================] - 162s 27ms/step - loss: 2.9261\n",
            "6000/6000 [==============================] - 168s 28ms/step - loss: 2.8985\n",
            "6000/6000 [==============================] - 165s 28ms/step - loss: 2.8808\n",
            "6000/6000 [==============================] - 159s 26ms/step - loss: 2.8602\n",
            "6000/6000 [==============================] - 158s 26ms/step - loss: 2.8474\n",
            "6000/6000 [==============================] - 159s 26ms/step - loss: 2.8305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpZLwnA4EzuP",
        "outputId": "19114550-1b7a-4cf3-e695-2a9a75ac7e91"
      },
      "source": [
        "'''\n",
        "SAVE MODEL\n",
        "'''\n",
        "modelname = 'pruned50quant-ResNet-quantized-LSTM'\n",
        "inputshape = list(train_data[1].values())[0].shape[1]\n",
        "save_quant(quant_aware_model,inputshape,modelname,ty='quant-aware-training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Fall20/10617_IDL/Project/models-v2/quant-aware-training/pruned50quant-ResNet-quantized-LSTM/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Fall20/10617_IDL/Project/models-v2/quant-aware-training/pruned50quant-ResNet-quantized-LSTM/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip_8tkmHfCdk"
      },
      "source": [
        "### EVALUATION FOR TENSORFLOW LITE MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irqLVk7JJ5Vi"
      },
      "source": [
        "# generate a description for an image\n",
        "def generate_desc_interpreter(interpreter, tokenizer, photo, maxlength, inp_ind, out_ind):\n",
        "    in_text = 'startseq'\n",
        "    for i in range(maxlength):\n",
        "      sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "      sequence = pad_sequences([sequence], maxlen=maxlength)\n",
        "      photo = photo.astype(np.float32)\n",
        "      sequence = sequence.astype(np.float32)\n",
        "      interpreter.set_tensor(inp_ind[0],photo)\n",
        "      interpreter.set_tensor(inp_ind[1],sequence)\n",
        "      interpreter.invoke()\n",
        "      output = interpreter.tensor(out_ind)\n",
        "      yhat = output()[0]\n",
        "      yhat = argmax(yhat)\n",
        "      word = word_for_id(yhat, tokenizer)\n",
        "      if word is None:\n",
        "        break\n",
        "      in_text += ' ' + word\n",
        "      if word == 'endseq':\n",
        "        break\n",
        "    return in_text\n",
        "\n",
        "def evaluate_interpreter(interpreter, descriptions, photos, tokenizer, maxlength):\n",
        "    actual, predicted = list(), list()\n",
        "    input_index = []\n",
        "    if interpreter.get_input_details()[0]['shape'][1] == 34:\n",
        "      input_index.append(interpreter.get_input_details()[1][\"index\"])\n",
        "      input_index.append(interpreter.get_input_details()[0][\"index\"])\n",
        "    else:\n",
        "      input_index.append(interpreter.get_input_details()[0][\"index\"])\n",
        "      input_index.append(interpreter.get_input_details()[1][\"index\"])\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    # input_index.append(interpreter.get_input_details()[0][\"index\"])\n",
        "    # input_index.append(interpreter.get_input_details()[1][\"index\"])\n",
        "    # output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    for key, desc_list in descriptions.items():\n",
        "      yhat = generate_desc_interpreter(interpreter, tokenizer, photos[key], maxlength, input_index, output_index)\n",
        "      references = [d.split() for d in desc_list]\n",
        "      actual.append(references)\n",
        "      predicted.append(yhat.split())\n",
        "\t\n",
        "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "\n",
        "def evaluate_call_interpreter(interpreter,feat_fname):\n",
        "\n",
        "    # load training dataset (6K)\n",
        "    filename = FOLDERPATH+'dataset/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "    train = load_set(filename)\n",
        "    train_descriptions = load_clean_descriptions(FOLDERPATH+'dataset/descriptions.txt', train)\n",
        "    tokenizer = create_tokenizer(train_descriptions)\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    maxlength = max_length(train_descriptions)\n",
        "\n",
        "    # load test set\n",
        "    filename = FOLDERPATH+'dataset/Flickr8k_text/Flickr_8k.testImages.txt'\n",
        "    test = load_set(filename)\n",
        "    test_descriptions = load_clean_descriptions(FOLDERPATH+'dataset/descriptions.txt', test)\n",
        "    test_features = load_photo_features(FOLDERPATH+'dataset/{:}.pkl'.format(feat_fname), test)\n",
        "\n",
        "    # evaluate model\n",
        "    start = time.time()\n",
        "    evaluate_interpreter(interpreter, test_descriptions, test_features, tokenizer, maxlength)\n",
        "    print(\"\\nTime taken: \", (time.time()-start)/60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc9-E3z_rCvu"
      },
      "source": [
        "#### VGG16 RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EERf5qjkMzGs"
      },
      "source": [
        "##### BASELINE VGG QUANTIZED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-J6Wfs8fgli",
        "outputId": "3a0d10ba-c7a6-4cc5-d40a-47039b4930d9"
      },
      "source": [
        "modelname = 'baseline-VGG16-quantized-LSTM'\n",
        "featuresname = 'features_VGG'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/quant-aware-training/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.521598\n",
            "BLEU-2: 0.280835\n",
            "BLEU-3: 0.186640\n",
            "BLEU-4: 0.082050\n",
            "\n",
            "Time taken:  1.724222469329834\n",
            "Quantized model in Mb: 21.09545135498047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7r1O5AsXGTT"
      },
      "source": [
        "##### QUANTIZED VGG QUANTIZED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ7ZTWsjXDXg",
        "outputId": "d839f17d-92b9-4026-bf3b-ba7f9ad99680"
      },
      "source": [
        "modelname = 'quantized-VGG16-quantized-LSTM'\n",
        "featuresname = 'features_VGGQ'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/quant-aware-training/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.568242\n",
            "BLEU-2: 0.304966\n",
            "BLEU-3: 0.199659\n",
            "BLEU-4: 0.084858\n",
            "\n",
            "Time taken:  1.6369754473368328\n",
            "Quantized model in Mb: 21.09540557861328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U5C_BM7VUbZ"
      },
      "source": [
        "##### PRUNED50 VGG QUANTIZED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFyv_Vy8VVfe",
        "outputId": "6839b4ed-e3f0-4104-edb6-ce4765b0903d"
      },
      "source": [
        "modelname = 'pruned50-VGG16-quantized-LSTM'\n",
        "featuresname = 'features_VGGP50'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/quant-aware-training/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.523818\n",
            "BLEU-2: 0.223779\n",
            "BLEU-3: 0.137816\n",
            "BLEU-4: 0.054964\n",
            "\n",
            "Time taken:  1.43951096534729\n",
            "Quantized model in Mb: 17.345420837402344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM--lzU9Pnze"
      },
      "source": [
        "##### PRUNED50QUANT VGG QUANTIZED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp4T3TJ3PtwG",
        "outputId": "b7276cc7-cfcc-42dd-e14d-2133801a26b1"
      },
      "source": [
        "modelname = 'pruned50quant-VGG16-quantized-LSTM'\n",
        "featuresname = 'features_VGGP50Q'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/quant-aware-training/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.459181\n",
            "BLEU-2: 0.187004\n",
            "BLEU-3: 0.110588\n",
            "BLEU-4: 0.039175\n",
            "\n",
            "Time taken:  1.7875096837679545\n",
            "Quantized model in Mb: 17.193092346191406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VbQObkcrLxK"
      },
      "source": [
        "#### RESNET RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOtQPy2hN23V"
      },
      "source": [
        "##### BASELINE RESNET QUANTIZED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWRZrc-ZN6XQ",
        "outputId": "d7d4ab87-b813-42a1-9f21-72b7433147f8"
      },
      "source": [
        "modelname = 'baseline-ResNet-quantized-LSTM'\n",
        "featuresname = 'features_ResNet'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/quant-aware-training/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.503329\n",
            "BLEU-2: 0.262821\n",
            "BLEU-3: 0.178434\n",
            "BLEU-4: 0.079824\n",
            "\n",
            "Time taken:  1.653984014193217\n",
            "Quantized model in Mb: 19.095436096191406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GtJtRtQjWBV"
      },
      "source": [
        "##### QUANTIZED RESNET QUANTIZED LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32e0_ebsjXJX",
        "outputId": "6a20b968-de82-4699-8f3d-bb86c1a0e62a"
      },
      "source": [
        "modelname = 'quantized-ResNet-quantized-LSTM'\n",
        "featuresname = 'features_ResNetQ'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/quant-aware-training/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.483891\n",
            "BLEU-2: 0.248940\n",
            "BLEU-3: 0.167475\n",
            "BLEU-4: 0.072523\n",
            "\n",
            "Time taken:  1.7938211917877198\n",
            "Quantized model in Mb: 21.095436096191406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W32LJBFwvMul"
      },
      "source": [
        "##### PRUNED50 RESNET QUANTIZED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA2N3LTwvQRg",
        "outputId": "cc0bc615-43d2-4fc8-d6b5-505a2da4b96f"
      },
      "source": [
        "modelname = 'pruned50-ResNet-quantized-LSTM'\n",
        "featuresname = 'features_ResNetP50'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/quant-aware-training/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.514513\n",
            "BLEU-2: 0.252351\n",
            "BLEU-3: 0.149940\n",
            "BLEU-4: 0.062642\n",
            "\n",
            "Time taken:  1.020120088259379\n",
            "Quantized model in Mb: 18.07196807861328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjixHgXevXHK"
      },
      "source": [
        "##### PRUNED50QUANT RESNET QUANTIZED LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZamKfqSWvbvX",
        "outputId": "46ee07e1-f074-4cc0-d220-e2ee7fac964c"
      },
      "source": [
        "modelname = 'pruned50quant-ResNet-quantized-LSTM'\n",
        "featuresname = 'features_ResNetP50Q'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/quant-aware-training/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.442108\n",
            "BLEU-2: 0.165824\n",
            "BLEU-3: 0.091904\n",
            "BLEU-4: 0.031607\n",
            "\n",
            "Time taken:  1.329277722040812\n",
            "Quantized model in Mb: 17.193092346191406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o3qnJCCRniC"
      },
      "source": [
        "### POST TRAINING QUANTIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw9t0_TZSBkb",
        "outputId": "d296acb7-a062-4014-a0cc-ea0d9e6b9cfb"
      },
      "source": [
        "'''\n",
        "QUANTIZE POST TRAINING\n",
        "'''\n",
        "baselinemodelname = 'pruned50-VGG16-baseline-LSTM'\n",
        "baseline_model = load_model(FOLDERPATH+'models-v2/baselines/'+baselinemodelname+'.h5')\n",
        "inputshape = baseline_model.input[0].shape[1]\n",
        "save_quant(baseline_model,inputshape,modeldir='pruned50-VGG16-quantized-LSTM',ty='post-training-quant')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Fall20/10617_IDL/Project/models-v2/post-training-quant/pruned50-VGG16-quantized-LSTM/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0AiqYbE_Xnn"
      },
      "source": [
        "##### BASELINE VGG QUANTIZED LSTM (post training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfCxG-jR8epI",
        "outputId": "13ba081b-3b4f-40de-c5f1-bbfe07bb756f"
      },
      "source": [
        "modelname = 'baseline-VGG16-quantized-LSTM'\n",
        "featuresname = 'features_VGG'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/post-training-quant/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.230242\n",
            "BLEU-2: 0.077129\n",
            "BLEU-3: 0.043668\n",
            "BLEU-4: 0.018815\n",
            "\n",
            "Time taken:  0.3262763977050781\n",
            "Quantized model in Mb: 21.09308624267578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgdQRcUU_yC7"
      },
      "source": [
        "##### QUANTIZED VGG QUANTIZED LSTM (post training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRC0gxIg86-N",
        "outputId": "67cee8ac-f06f-4d59-9899-a63550e27441"
      },
      "source": [
        "modelname = 'quantized-VGG16-quantized-LSTM'\n",
        "featuresname = 'features_VGGQ'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/post-training-quant/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.050313\n",
            "BLEU-2: 0.050313\n",
            "BLEU-3: 0.050313\n",
            "BLEU-4: 0.050313\n",
            "\n",
            "Time taken:  0.11966217358907064\n",
            "Quantized model in Mb: 21.09308624267578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3XpR9LeAjMb"
      },
      "source": [
        "##### BASELINE RESNET QUANTIZED LSTM (post training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvGKtxww_72y",
        "outputId": "05d9d7b3-8ba3-46bd-be93-28174c952f26"
      },
      "source": [
        "modelname = 'baseline-ResNet-quantized-LSTM'\n",
        "featuresname = 'features_ResNet'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/post-training-quant/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.051701\n",
            "BLEU-2: 0.002298\n",
            "BLEU-3: 0.007991\n",
            "BLEU-4: 0.010913\n",
            "\n",
            "Time taken:  0.1322492003440857\n",
            "Quantized model in Mb: 19.093082427978516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DgfxIQAzIl"
      },
      "source": [
        "##### QUANTIZED RESNET QUANTIZED LSTM (post training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlycOK86AivV",
        "outputId": "14fe73af-a2d8-4c98-ad55-b979e253e0f7"
      },
      "source": [
        "modelname = 'quantized-ResNet-quantized-LSTM'\n",
        "featuresname = 'features_ResNetQ'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/post-training-quant/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.050313\n",
            "BLEU-2: 0.050313\n",
            "BLEU-3: 0.050313\n",
            "BLEU-4: 0.050313\n",
            "\n",
            "Time taken:  0.12165356874465942\n",
            "Quantized model in Mb: 21.09308624267578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr9NSZL8KSg8"
      },
      "source": [
        "##### PRUNED50 VGG QUANTIZED LSTM (post training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "3-R5OU2EA06n",
        "outputId": "93d025a1-688b-4dd7-e72b-bdf5bd65b673"
      },
      "source": [
        "modelname = 'pruned50-VGG16-quantized-LSTM'\n",
        "featuresname = 'features_VGGP50'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FOLDERPATH+'models-v2/post-training-quant/'+modelname)\n",
        "tflite_model = converter.convert()\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "evaluate_call_interpreter(interpreter,featuresname)\n",
        "get_quant_model_size(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ea98cead3191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodelname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pruned50-VGG16-quantized-LSTM'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeaturesname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'features_VGGP50'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOLDERPATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'models-v2/post-training-quant/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, signature_keys, tags)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m       \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignature_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m       \u001b[0msignature_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \"\"\"\n\u001b[0;32m--> 603\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m--> 614\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   debug_info_path = os.path.join(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/drive/MyDrive/Fall20/10617_IDL/Project/models-v2/post-training-quant/pruned50-VGG16-quantized-LSTM/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyVZBrYvKoX0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}