{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Compressed-MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBRo1ypvd8Hd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzNfnsxll5Th"
      },
      "source": [
        " !pip install -q tensorflow-model-optimization\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "favCO06-mUqJ",
        "outputId": "5b8ccba5-f553-46fd-e647-4dea294babb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "import pickle as pk\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import History \n",
        "history = History()\n",
        "\n",
        "np.random.seed(25)\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09a1RfWEmqlQ"
      },
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture.\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(5, 5), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Conv2D(filters=12,kernel_size=(3,3),activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10)\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk1iurQ_Bv0T"
      },
      "source": [
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "unpruned_model=model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  validation_split=0.1,\n",
        "  callbacks=[history]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16AGAA7PuztJ"
      },
      "source": [
        "\n",
        "dir_name = '/content/drive/My Drive/Fall2020/10617_IDL/Project/Baseline'\n",
        "fname = dir_name+'Baseline.h5'\n",
        "model.save(fname)\n",
        "\n",
        "fname = 'log_dir-{d}.pkl'.format(d=folder_name)\n",
        "with open(dir_name+fname,'wb') as f:\n",
        "  pk.dump(logdir,f)\n",
        "f.close()\n",
        "\n",
        "metric = (unpruned_model.history['accuracy'],unpruned_model.history['val_accuracy'],\n",
        "          unpruned_model.history['loss'],unpruned_model.history['val_loss'])\n",
        "fname = 'metric-{d}.pkl'.format(d=folder_name)\n",
        "with open(dir_name+fname,'wb') as f:\n",
        "  pk.dump(metric,f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gHFqGAErL0A"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = train_images.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0,\n",
        "                                                               final_sparsity=0.95,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "pruned_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "pruned_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFLtOMBSsBc5"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "from keras.callbacks import History \n",
        "history = History()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "  history\n",
        "]\n",
        "  \n",
        "pruned_history=pruned_model.fit(train_images, train_labels,\n",
        "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                  callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJFpIbkxFpG8"
      },
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24CzyX6utWnh"
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WJBp3EJ0t19"
      },
      "source": [
        "fin_sp=0.95\n",
        "folder_name = str(int(fin_sp*100))\n",
        "dir_name = '/content/drive/My Drive/Fall2020/10617_IDL/Project/sparse-{d}/'.format(d=folder_name)\n",
        "fname = dir_name+'pruned-model-{d}.h5'.format(d=folder_name)\n",
        "model_for_export.save(fname)\n",
        "\n",
        "fname = 'log_dir-{d}.pkl'.format(d=folder_name)\n",
        "with open(dir_name+fname,'wb') as f:\n",
        "  pk.dump(logdir,f)\n",
        "f.close()\n",
        "\n",
        "metric = (pruned_history.history['accuracy'],pruned_history.history['val_accuracy'],\n",
        "          pruned_history.history['loss'],pruned_history.history['val_loss'])\n",
        "fname = 'metric-{d}.pkl'.format(d=folder_name)\n",
        "with open(dir_name+fname,'wb') as f:\n",
        "  pk.dump(metric,f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdx6mm3w3_Pq"
      },
      "source": [
        "def NNZ(weights):\n",
        "  zeroCount = 0\n",
        "  for ele in weights:\n",
        "    if ele == 0.0:\n",
        "      zeroCount += 1\n",
        "\n",
        "  return zeroCount\n",
        "\n",
        "\n",
        "\n",
        "allWeights = np.array([1],dtype=float)\n",
        "for weight in model_for_export.get_weights():\n",
        "  allWeights = np.concatenate((allWeights,weight.flatten()))\n",
        "nnz = NNZ(allWeights[1:])\n",
        "print(\"Number of Non-zero Params: \", nnz)\n",
        "print(\"Sparsity - {d}%\".format(d=np.round(nnz/allWeights[1:].shape[0]*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSEfA0FS4pnR"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX4bIrgh4sep"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-aFJG_m4vkQ"
      },
      "source": [
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljJ5ee9e4yRI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "figure,((ax1,ax2))=plt.subplots(nrows=1,ncols=2,sharex=False,sharey=False)\n",
        "\n",
        "figure.set_figwidth(15)\n",
        "sparsity=[50,80,90,95]\n",
        "record={}\n",
        "x=range(epochs)\n",
        "for i in range(len(sparsity)):\n",
        "\n",
        "    with open('/content/drive/My Drive/Fall2020/10617_IDL/Project/sparse-{d}/metric-{d}.pkl'.format(d=sparsity[i]), 'rb') as f:\n",
        "      unpickler = pk.Unpickler(f)\n",
        "      metric=unpickler.load()\n",
        "      train_acc=metric[0]\n",
        "      test_acc=metric[1]\n",
        "    ax1.plot(x,train_acc,'*-',label='Sparsity:{d}%'.format(d=sparsity[i]))\n",
        "    ax2.plot(x,test_acc,'*-',label='Sparsity:{d}%'.format(d=sparsity[i]))\n",
        "\n",
        "ax1.set(xlabel='Epochs', ylabel='Train Accuracy')\n",
        "ax2.set(xlabel='Epochs', ylabel='Test Accuracy')\n",
        "ax1.legend(loc='best', prop={'size': 7})\n",
        "ax2.legend(loc='best', prop={'size': 7})\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HphObqt_IW-Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}